{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muskan-asudani/customer-satisfaction-score-prediction/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AM1rcxnH0Pr"
      },
      "source": [
        "# Customer Satisfaction Score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project made by:\n",
        "\n",
        "*  Muskan Asudani  roll no. 06\n",
        "*  Aditya Shukla roll no. 42\n",
        "\n",
        "\n",
        "                "
      ],
      "metadata": {
        "id": "fMXnocgKMh-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Customer Feedback and Satisfaction Dataset is a  dataset designed to analyze and predict customer satisfaction based on various demographic and behavioral factors. It contains data for 38,444 customers, capturing their feedback on products and services in a structured format."
      ],
      "metadata": {
        "id": "DG6-FnKKsMgn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz19ErUVG334"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHVuHBwlGwQT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns   #visualisation\n",
        "import matplotlib.pyplot as plt    #visualisation\n",
        "%matplotlib inline\n",
        "#to display the plots immediatedly below the code\n",
        "sns.set(color_codes=True)\n",
        "#to enable us to use shorthand color codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcYk-5ZJEgb"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the data was downloaded from kaggle and uploaded from the device."
      ],
      "metadata": {
        "id": "ZGVcZOQN16oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('customer_feedback_satisfaction.csv')"
      ],
      "metadata": {
        "id": "n1Pfkuc614fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpmUn9rTMYJP"
      },
      "source": [
        "## Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "hGaIRUrop8fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVYUSlOM7EW"
      },
      "outputs": [],
      "source": [
        "data.describe() #all the details about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGLnLw-kLxXD",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data.head() #to show the first five entries in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsX-fWiOM1WT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data.tail() #to show the last entries in the dataset  default=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLEwlUPKM4f1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data.dtypes #check the types of data present"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.values"
      ],
      "metadata": {
        "id": "_cqReZhiqsrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2i2_wP2QE8y"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSkShWl-NL84"
      },
      "source": [
        "**Dropping irrelevant columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ24fm4DNLk7"
      },
      "outputs": [],
      "source": [
        "data=data.drop(['CustomerID'],axis=1)  #dropping the customer id column here because it won't factor in for the prediction #axis=1 implies we are dropping a coloumn\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_5hCyTNUbj"
      },
      "source": [
        "**Renaming the rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXr5rY2xNXWO"
      },
      "outputs": [],
      "source": [
        "#this can be used to give the columns short alternative names so they are easier to access\n",
        "data=data.rename(columns={'SatisfactionScore':'SS'})\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFj7qRxnNoaV"
      },
      "source": [
        "**Dropping duplicate rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-Amoy-rNnjq"
      },
      "outputs": [],
      "source": [
        "if data.duplicated().any():\n",
        "  data=data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWiGfhjRCKmt"
      },
      "source": [
        "**Dropping null values**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data.isna(): Returns a DataFrame of the same shape as data, with True indicating the presence of a NaN in each cell.\n",
        "\n",
        "data.isna().any(): For each column, it checks if there are any True values (i.e., any NaN values). This results in a Series where each entry is True if the column contains at least one NaN.\n",
        "\n",
        "data.isna().any().any(): The second .any() checks across the entire Series of columns, returning True if any column has at least one missing value. Essentially, this checks if there's any missing value in the entire DataFrame.\n",
        "\n",
        "data.dropna(): If any missing value is found, dropna() is called to remove all rows containing NaNs."
      ],
      "metadata": {
        "id": "A2yO0BZxfHBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUM2a9mlCW_b"
      },
      "outputs": [],
      "source": [
        "if data.isna().any().any():\n",
        "  data=data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OR Run this to see what each function does**"
      ],
      "metadata": {
        "id": "BBi65-M-e_sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data.isna()"
      ],
      "metadata": {
        "id": "0LCJvdALeMC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.isna().any()"
      ],
      "metadata": {
        "id": "7mdqjgiIeQ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#na=data.isna().any().any()"
      ],
      "metadata": {
        "id": "2fJSdUr9eXz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if na:\n",
        "  #data = data.dropna()"
      ],
      "metadata": {
        "id": "0gUqLrPLfEgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3CouToOIBb7"
      },
      "source": [
        "**Classifying the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression requires numeric inputs"
      ],
      "metadata": {
        "id": "WYi9j5W3AlzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary library"
      ],
      "metadata": {
        "id": "asMun-DfAskl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "iSw0Uk28AqSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encodeing the Gender Column"
      ],
      "metadata": {
        "id": "_l7RrLLvBk76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder object\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # sparse=False for array output\n",
        "\n",
        "# Fit the encoder to the 'Gender' column\n",
        "encoder.fit(data[['Gender']])  # Assuming your DataFrame is named 'data'\n",
        "\n",
        "# Transform the 'Gender' column\n",
        "encoded_gender = encoder.transform(data[['Gender']])\n",
        "\n",
        "# Create new columns from the encoded data\n",
        "gender_df = pd.DataFrame(encoded_gender, columns=encoder.get_feature_names_out(['Gender']))\n",
        "\n",
        "# Concatenate the encoded columns with the original DataFrame\n",
        "data = pd.concat([data, gender_df], axis=1)\n",
        "\n",
        "# Drop the original 'Gender' column\n",
        "data = data.drop('Gender', axis=1)"
      ],
      "metadata": {
        "id": "GEYtWL6NAxUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the Country column"
      ],
      "metadata": {
        "id": "Y2MCWpsjCGzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder object\n",
        "encoder_country = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "# Fit the encoder to the 'Country' column\n",
        "encoder_country.fit(data[['Country']])\n",
        "\n",
        "# Transform the 'Country' column\n",
        "encoded_country = encoder_country.transform(data[['Country']])\n",
        "\n",
        "# Create new columns from the encoded data\n",
        "country_df = pd.DataFrame(encoded_country, columns=encoder_country.get_feature_names_out(['Country']))\n",
        "\n",
        "# Concatenate the encoded columns with the original DataFrame\n",
        "data = pd.concat([data, country_df], axis=1)\n",
        "\n",
        "# Drop the original 'Country' column\n",
        "data = data.drop('Country', axis=1)"
      ],
      "metadata": {
        "id": "-GtCcqtOCLQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feedback_mapping = {'Low': 1, 'Medium': 2, 'High': 3}\n",
        "\n",
        "# Apply the mapping to the 'FeedbackScore' column\n",
        "data['FeedbackScore'] = data['FeedbackScore'].map(feedback_mapping)"
      ],
      "metadata": {
        "id": "3uDAZGSJCUxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loyalty_mapping={'Gold':3,'Silver':2,'Bronze':1}\n",
        "data['LoyaltyLevel']=data['LoyaltyLevel'].map(loyalty_mapping)"
      ],
      "metadata": {
        "id": "jTFFgxTrCcEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgScF8a7LImA"
      },
      "source": [
        "## Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXH2eFE_LL1h"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['ServiceQuality'], data['SS'])  # Create scatter plot\n",
        "plt.xlabel('Service Quality')  # Set x-axis label\n",
        "plt.ylabel('Satisfaction Score')  # Set y-axis label\n",
        "plt.title('Service Quality vs Satisfaction Score')  # Set plot title\n",
        "plt.show()  # Display the plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['ProductQuality'], data['SS'])  # Create scatter plot\n",
        "plt.xlabel('Product Quality')  # Set x-axis label\n",
        "plt.ylabel('Satisfaction Score')  # Set y-axis label\n",
        "plt.title('Product Quality vs Satisfaction Score')  # Set plot title\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "_-ZwRRwv9YTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PczDJ1XUN66w"
      },
      "source": [
        "## Test-Train-Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgPUe-4DR7G"
      },
      "source": [
        "**This function randomly splits the data into the desired proportions (e.g., 80% for training, 20% for testing).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ-ab2w2OCkF"
      },
      "outputs": [],
      "source": [
        "#importing necessary modules and functions\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgHybQSMEWeP"
      },
      "outputs": [],
      "source": [
        "# Features and target variable\n",
        "x = data.drop('SS', axis=1) #enter target variable here and in the code below\n",
        "y = data['SS']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cGMrF02SDbOH"
      },
      "outputs": [],
      "source": [
        "## Split the data\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.2)\n",
        "x_train.count(),x_test.count(),y_train.count(),y_test.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BD5THt1nEbbf"
      },
      "outputs": [],
      "source": [
        "x_train.head(),y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzbo8XyOEbm"
      },
      "source": [
        "## ModelTraining"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "cC8_C5G3_ves"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "l5J6meme_uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "UGBv4c_nF95O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modellr = LinearRegression()  # Create a Linear Regression object\n",
        "modellr.fit(x_train, y_train)  # Train the model"
      ],
      "metadata": {
        "id": "g_qunINA_8TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Regression**"
      ],
      "metadata": {
        "id": "FyY-Myy5GCqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modeldt = DecisionTreeRegressor()\n",
        "modeldt.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "hyr0XdhFGPgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regression**"
      ],
      "metadata": {
        "id": "q9bx04q8GHCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelrf = RandomForestRegressor()\n",
        "modelrf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "yRuSyJvcGXh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Regression (SVR)**"
      ],
      "metadata": {
        "id": "jAgSSq35GLl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelsvr = SVR()\n",
        "modelsvr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "1j_Y5A78Ghml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlKQgqFxH1MT"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_SfBsveFQIo"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR-MBBAQEif5"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred_lr = modellr.predict(x_test)\n",
        "y_pred_dt = modeldt.predict(x_test)\n",
        "y_pred_rt = modelrf.predict(x_test)\n",
        "y_pred_svr = modelsvr.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uhaEzmyFFO5o"
      },
      "outputs": [],
      "source": [
        "print(f'Linear Regression prediction: {y_pred_lr}')\n",
        "print(f'Decision Tree Regression prediction: {y_pred_dt}')\n",
        "print(f'Random Forest Regression prediction: {y_pred_rt}')\n",
        "print(f'Support Vector Regression prediction: {y_pred_svr}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_VcGgY2TFZ_n"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation"
      ],
      "metadata": {
        "id": "VHQDN2tbguSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(model, x, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Average cross-validation score:\", cv_scores.mean())"
      ],
      "metadata": {
        "id": "LuO3zaNngw20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean-squared-error"
      ],
      "metadata": {
        "id": "1xVVOUrfDuG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "mse1 = mean_squared_error(y_test, y_pred_lr)  # Calculate Mean Squared Error for linear regression\n",
        "r2_1 = r2_score(y_test, y_pred_lr)  # Calculate R-squared\n",
        "\n",
        "mse2 = mean_squared_error(y_test, y_pred_dt)  # Calculate Mean Squared Error for decision tree regression\n",
        "r2_2 = r2_score(y_test, y_pred_dt)  # Calculate R-squared\n",
        "\n",
        "mse3 = mean_squared_error(y_test, y_pred_rt)  # Calculate Mean Squared Error for random forest regression\n",
        "r2_3 = r2_score(y_test, y_pred_rt)  # Calculate R-squared\n",
        "\n",
        "mse4 = mean_squared_error(y_test, y_pred_svr)  # Calculate Mean Squared Error for Support vector regression\n",
        "r2_4 = r2_score(y_test, y_pred_svr)  # Calculate R-squared\n",
        "\n",
        "\n",
        "mse={'Linear Regression':mse1,'Decision Tree Regression':mse2,'Random Forest Regression':mse3,'Support Vector Regression':mse4}\n",
        "\n",
        "r2_score={'Linear Regression':r2_1,'Decision Tree Regression':r2_2,'Random Forest Regression':r2_3,'Support Vector Regression':r2_4}\n",
        "\n",
        "print(mean_squared_error)\n",
        "for key, value in mse.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print('\\nr2_score: ')\n",
        "for key, value in r2_score.items():\n",
        "  print(key , value)"
      ],
      "metadata": {
        "id": "9qff5FxbDkQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "PYx5UKdILhqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Model: The model with the lowest MSE and the highest R2 is generally considered the best-performing model for regression tasks.\n",
        "\n",
        "We chose the random forest regressor model and linear regression here."
      ],
      "metadata": {
        "id": "K8hxrvkPN9Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit to training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(best_rf_model)"
      ],
      "metadata": {
        "id": "cIhhDhnNLllL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "    'positive': [True, False]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit to training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_linear_model = grid_search.best_estimator_\n",
        "print(best_linear_model)"
      ],
      "metadata": {
        "id": "LtKCT0B5OJ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woVkJaiESJMg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OpmUn9rTMYJP"
      ],
      "authorship_tag": "ABX9TyONWQH5K7zsSLJfjVTSxkTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}